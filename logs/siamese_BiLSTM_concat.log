258745/258745 [==============================] - 600s 2ms/step - loss: 0.4381 - acc: 0.7933 - val_loss: 0.5284 - val_acc: 0.7460
Epoch 17/50
258745/258745 [==============================] - 598s 2ms/step - loss: 0.4362 - acc: 0.7947 - val_loss: 0.5140 - val_acc: 0.7567
Epoch 18/50
258745/258745 [==============================] - 599s 2ms/step - loss: 0.4322 - acc: 0.7968 - val_loss: 0.5036 - val_acc: 0.7591
Epoch 19/50
258745/258745 [==============================] - 599s 2ms/step - loss: 0.4304 - acc: 0.7974 - val_loss: 0.5096 - val_acc: 0.7587
Epoch 20/50
258745/258745 [==============================] - 600s 2ms/step - loss: 0.4301 - acc: 0.7978 - val_loss: 0.5193 - val_acc: 0.7518
Epoch 21/50
258745/258745 [==============================] - 599s 2ms/step - loss: 0.4283 - acc: 0.7987 - val_loss: 0.5146 - val_acc: 0.7578
Epoch 22/50
258745/258745 [==============================] - 598s 2ms/step - loss: 0.4257 - acc: 0.7993 - val_loss: 0.5135 - val_acc: 0.7587
Epoch 23/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.4237 - acc: 0.8012Epoch 00023: val_acc improved from 0.76062 to 0.76161, saving model to ../models/weights-impro258745/258745 [==============================] - 600s 2ms/step - loss: 0.4238 - acc: 0.8011 - val_loss: 0.5078 - val_acc: 0.7616
Epoch 24/50
258745/258745 [==============================] - 595s 2ms/step - loss: 0.4230 - acc: 0.8023 - val_loss: 0.5116 - val_acc: 0.7574
Epoch 25/50
258745/258745 [==============================] - 598s 2ms/step - loss: 0.4219 - acc: 0.8027 - val_loss: 0.5280 - val_acc: 0.7575
Epoch 26/50
258745/258745 [==============================] - 598s 2ms/step - loss: 0.4200 - acc: 0.8033 - val_loss: 0.5181 - val_acc: 0.7548
Epoch 27/50
258745/258745 [==============================] - 598s 2ms/step - loss: 0.4181 - acc: 0.8055 - val_loss: 0.5219 - val_acc: 0.7519
Epoch 28/50
258745/258745 [==============================] - 599s 2ms/step - loss: 0.4175 - acc: 0.8047 - val_loss: 0.5267 - val_acc: 0.7508
Epoch 29/50
258745/258745 [==============================] - 599s 2ms/step - loss: 0.4176 - acc: 0.8045 - val_loss: 0.5142 - val_acc: 0.7576
Epoch 30/50
258745/258745 [==============================] - 600s 2ms/step - loss: 0.4167 - acc: 0.8055 - val_loss: 0.5234 - val_acc: 0.7539

Metrics on test dataset
precision: [ 0.81183632  0.67660055]
recall: [ 0.80891995  0.6807394 ]
fscore: [ 0.81037551  0.67866367]
support: [50942 29916]
[[41208  9734]
 [ 9551 20365]]
Accuracy: (20365.0+41208)/(41208+9734+9551+20365) = 0.76149546117

---------FIXED---------------
258688/258745 [============================>.] - ETA: 0s - loss: 0.2765 - acc: 0.8803Epoch 00011: val_acc improved from 0.82154 to 0.82258, saving model to ../models/weights-impro258745/258745 [==============================] - 597s 2ms/step - loss: 0.2765 - acc: 0.8803 - val_loss: 0.4031 - val_acc: 0.8226
Epoch 12/30
258688/258745 [============================>.] - ETA: 0s - loss: 0.2671 - acc: 0.8852Epoch 00012: val_acc improved from 0.82258 to 0.82422, saving model to ../models/weights-impro258745/258745 [==============================] - 597s 2ms/step - loss: 0.2671 - acc: 0.8852 - val_loss: 0.4078 - val_acc: 0.8242
Epoch 13/30
258745/258745 [==============================] - 597s 2ms/step - loss: 0.2590 - acc: 0.8887 - val_loss: 0.4164 - val_acc: 0.8190
Epoch 14/30
258745/258745 [==============================] - 597s 2ms/step - loss: 0.2519 - acc: 0.8918 - val_loss: 0.4228 - val_acc: 0.8221
Epoch 15/30
258688/258745 [============================>.] - ETA: 0s - loss: 0.2443 - acc: 0.8959Epoch 00015: val_acc improved from 0.82422 to 0.82760, saving model to ../models/weights-impro258745/258745 [==============================] - 598s 2ms/step - loss: 0.2443 - acc: 0.8959 - val_loss: 0.4354 - val_acc: 0.8276
Epoch 16/30
258745/258745 [==============================] - 597s 2ms/step - loss: 0.2381 - acc: 0.8995 - val_loss: 0.4516 - val_acc: 0.8221
Epoch 17/30
258745/258745 [==============================] - 596s 2ms/step - loss: 0.2320 - acc: 0.9014 - val_loss: 0.4299 - val_acc: 0.8257
Epoch 18/30
258745/258745 [==============================] - 597s 2ms/step - loss: 0.2258 - acc: 0.9049 - val_loss: 0.4516 - val_acc: 0.8249
Epoch 19/30
258745/258745 [==============================] - 596s 2ms/step - loss: 0.2224 - acc: 0.9069 - val_loss: 0.4523 - val_acc: 0.8230
Epoch 20/30
258745/258745 [==============================] - 596s 2ms/step - loss: 0.2166 - acc: 0.9094 - val_loss: 0.4446 - val_acc: 0.8221
Epoch 21/30
258745/258745 [==============================] - 596s 2ms/step - loss: 0.2120 - acc: 0.9114 - val_loss: 0.4708 - val_acc: 0.8210
Epoch 22/30
258745/258745 [==============================] - 597s 2ms/step - loss: 0.2086 - acc: 0.9138 - val_loss: 0.4605 - val_acc: 0.8236
Epoch 23/30
258745/258745 [==============================] - 596s 2ms/step - loss: 0.2053 - acc: 0.9150 - val_loss: 0.4754 - val_acc: 0.8274
Epoch 24/30
258745/258745 [==============================] - 596s 2ms/step - loss: 0.2013 - acc: 0.9163 - val_loss: 0.4765 - val_acc: 0.8243
Epoch 25/30
106496/258745 [===========>..................] - ETA: 5:20 - loss: 0.1945 - acc: 0.9191

Metrics on test dataset
precision: [ 0.86444475  0.76800908]
recall: [ 0.86351144  0.76942105]
fscore: [ 0.86397785  0.76871441]
support: [50942 29916]
[[43989  6953]
 [ 6898 23018]]
 Accuracy = (43989.0+23018)/(43989+6953+6898+23018) = 0.82869969576
