Using TensorFlow backend.
2017-12-01 20:18:28.218777: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-01 20:18:28.218840: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-01 20:18:28.218849: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-12-01 20:18:28.218854: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-01 20:18:28.218860: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-12-01 20:18:28.412052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-12-01 20:18:28.412726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:04.0
Total memory: 11.17GiB
Free memory: 11.09GiB
2017-12-01 20:18:28.412756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0
2017-12-01 20:18:28.412765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y
2017-12-01 20:18:28.412778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0)
Number of train data instances read 323432
Number of test data instances read 80858
Obtained processed training data
Obtained embeddings
2017-12-01 20:19:16.963394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0)
siamese_model.py:66: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(256, dropout=0.5, recurrent_dropout=0.5)`
  lstm.add(LSTM(256, dropout_W=0.5, dropout_U=0.5))
siamese_model.py:75: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.
  merged_output = merge([l_output, r_output], mode='concat')
/home/prakrutp/.local/lib/python2.7/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.
  name=name)
siamese_model.py:77: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, kernel_regularizer=<keras.reg..., activation="relu", bias_regularizer=<keras.reg...)`
  fcl = Dense(100, activation='relu', W_regularizer=l2(0.0001), b_regularizer=l2(0.0001))(merged_output)
siamese_model.py:78: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(50, kernel_regularizer=<keras.reg..., activation="relu", bias_regularizer=<keras.reg...)`
  fcl = Dense(50, activation='relu', W_regularizer=l2(0.0001), b_regularizer=l2(0.0001))(fcl)
siamese_model.py:80: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(25, kernel_regularizer=<keras.reg..., activation="relu", bias_regularizer=<keras.reg...)`
  fcl = Dense(25, activation='relu', W_regularizer=l2(0.0001), b_regularizer=l2(0.0001))(fcl)
siamese_model.py:83: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor("de..., inputs=[<tf.Tenso...)`
  model = Model(input=[l_input, r_input], output=prediction)
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_1 (InputLayer)            (None, 40)           0
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 40)           0
__________________________________________________________________________________________________
sequential_1 (Sequential)       (None, 100)          29277268    input_1[0][0]
                                                                 input_2[0][0]
__________________________________________________________________________________________________
merge_1 (Merge)                 (None, 200)          0           sequential_1[1][0]
                                                                 sequential_1[2][0]
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 100)          20100       merge_1[0][0]
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 50)           5050        dense_2[0][0]
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 25)           1275        dense_3[0][0]
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 1)            26          dense_4[0][0]
==================================================================================================
Total params: 29,303,719
Trainable params: 622,519
Non-trainable params: 28,681,200
__________________________________________________________________________________________________
None
Built Model
Training now...
Train on 258745 samples, validate on 64687 samples
Epoch 1/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.5846 - acc: 0.6955Epoch 00001: val_acc improved from -inf to 0.72939, saving model to ../models/weights-improvement-01-0.73.hdf5
258745/258745 [==============================] - 317s 1ms/step - loss: 0.5846 - acc: 0.6955 - val_loss: 0.5452 - val_acc: 0.7294
Epoch 2/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.5382 - acc: 0.7307Epoch 00002: val_acc improved from 0.72939 to 0.73868, saving model to ../models/weights-improvement-02-0.74.hdf5
258745/258745 [==============================] - 314s 1ms/step - loss: 0.5382 - acc: 0.7307 - val_loss: 0.5272 - val_acc: 0.7387
Epoch 3/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.5190 - acc: 0.7432Epoch 00003: val_acc did not improve
258745/258745 [==============================] - 315s 1ms/step - loss: 0.5190 - acc: 0.7432 - val_loss: 0.5211 - val_acc: 0.7380
Epoch 4/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.5055 - acc: 0.7509Epoch 00004: val_acc improved from 0.73868 to 0.75372, saving model to ../models/weights-improvement-04-0.75.hdf5
258745/258745 [==============================] - 311s 1ms/step - loss: 0.5055 - acc: 0.7509 - val_loss: 0.5132 - val_acc: 0.7537
Epoch 5/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.4952 - acc: 0.7588Epoch 00005: val_acc improved from 0.75372 to 0.75449, saving model to ../models/weights-improvement-05-0.75.hdf5
258745/258745 [==============================] - 314s 1ms/step - loss: 0.4952 - acc: 0.7588 - val_loss: 0.5069 - val_acc: 0.7545
Epoch 6/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.4862 - acc: 0.7643Epoch 00006: val_acc did not improve
258745/258745 [==============================] - 312s 1ms/step - loss: 0.4863 - acc: 0.7643 - val_loss: 0.5065 - val_acc: 0.7519
Epoch 7/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.4786 - acc: 0.7696Epoch 00007: val_acc improved from 0.75449 to 0.75729, saving model to ../models/weights-improvement-07-0.76.hdf5
258745/258745 [==============================] - 310s 1ms/step - loss: 0.4786 - acc: 0.7696 - val_loss: 0.5012 - val_acc: 0.7573
Epoch 8/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.4722 - acc: 0.7731Epoch 00008: val_acc did not improve
258745/258745 [==============================] - 310s 1ms/step - loss: 0.4722 - acc: 0.7731 - val_loss: 0.4980 - val_acc: 0.7567
Epoch 9/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.4657 - acc: 0.7772Epoch 00009: val_acc did not improve
258745/258745 [==============================] - 305s 1ms/step - loss: 0.4657 - acc: 0.7772 - val_loss: 0.5098 - val_acc: 0.7572
Epoch 10/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.4610 - acc: 0.7801Epoch 00010: val_acc improved from 0.75729 to 0.76020, saving model to ../models/weights-improvement-10-0.76.hdf5
258745/258745 [==============================] - 304s 1ms/step - loss: 0.4609 - acc: 0.7801 - val_loss: 0.4988 - val_acc: 0.7602
Epoch 11/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.4572 - acc: 0.7822Epoch 00011: val_acc did not improve
258745/258745 [==============================] - 302s 1ms/step - loss: 0.4572 - acc: 0.7822 - val_loss: 0.5096 - val_acc: 0.7564
Epoch 12/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.4523 - acc: 0.7855Epoch 00012: val_acc did not improve
258745/258745 [==============================] - 293s 1ms/step - loss: 0.4523 - acc: 0.7855 - val_loss: 0.5074 - val_acc: 0.7524
Epoch 13/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.4494 - acc: 0.7868Epoch 00013: val_acc did not improve
258745/258745 [==============================] - 298s 1ms/step - loss: 0.4494 - acc: 0.7868 - val_loss: 0.5099 - val_acc: 0.7538
Epoch 14/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.4451 - acc: 0.7894Epoch 00014: val_acc did not improve
258745/258745 [==============================] - 312s 1ms/step - loss: 0.4451 - acc: 0.7894 - val_loss: 0.5088 - val_acc: 0.7570
Epoch 15/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.4426 - acc: 0.7903Epoch 00015: val_acc did not improve
258745/258745 [==============================] - 309s 1ms/step - loss: 0.4426 - acc: 0.7903 - val_loss: 0.5042 - val_acc: 0.7582
Epoch 16/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.4408 - acc: 0.7913Epoch 00016: val_acc did not improve
258745/258745 [==============================] - 316s 1ms/step - loss: 0.4408 - acc: 0.7913 - val_loss: 0.5143 - val_acc: 0.7535
Epoch 17/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.4382 - acc: 0.7937Epoch 00017: val_acc did not improve
258745/258745 [==============================] - 302s 1ms/step - loss: 0.4382 - acc: 0.7937 - val_loss: 0.5086 - val_acc: 0.7587
Epoch 18/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.4349 - acc: 0.7955Epoch 00018: val_acc improved from 0.76020 to 0.76883, saving model to ../models/weights-improvement-18-0.77.hdf5
258745/258745 [==============================] - 299s 1ms/step - loss: 0.4349 - acc: 0.7955 - val_loss: 0.4995 - val_acc: 0.7688
Epoch 19/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.4340 - acc: 0.7966Epoch 00019: val_acc did not improve
258745/258745 [==============================] - 307s 1ms/step - loss: 0.4340 - acc: 0.7966 - val_loss: 0.5188 - val_acc: 0.7607
Epoch 20/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.4314 - acc: 0.7975Epoch 00020: val_acc did not improve
258745/258745 [==============================] - 292s 1ms/step - loss: 0.4314 - acc: 0.7975 - val_loss: 0.5319 - val_acc: 0.7512
Epoch 21/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.4306 - acc: 0.7984Epoch 00021: val_acc did not improve
258745/258745 [==============================] - 292s 1ms/step - loss: 0.4306 - acc: 0.7983 - val_loss: 0.5109 - val_acc: 0.7583
Epoch 22/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.4275 - acc: 0.8002Epoch 00022: val_acc did not improve
258745/258745 [==============================] - 291s 1ms/step - loss: 0.4274 - acc: 0.8002 - val_loss: 0.5179 - val_acc: 0.7590
Epoch 23/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.4269 - acc: 0.7999Epoch 00023: val_acc did not improve
258745/258745 [==============================] - 291s 1ms/step - loss: 0.4269 - acc: 0.8000 - val_loss: 0.5188 - val_acc: 0.7477
Epoch 24/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.4250 - acc: 0.8014Epoch 00024: val_acc did not improve
258745/258745 [==============================] - 295s 1ms/step - loss: 0.4250 - acc: 0.8014 - val_loss: 0.5290 - val_acc: 0.7507
Epoch 25/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.4251 - acc: 0.8020Epoch 00025: val_acc did not improve
258745/258745 [==============================] - 303s 1ms/step - loss: 0.4251 - acc: 0.8020 - val_loss: 0.5196 - val_acc: 0.7523
Epoch 26/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.4240 - acc: 0.8020Epoch 00026: val_acc did not improve
258745/258745 [==============================] - 302s 1ms/step - loss: 0.4241 - acc: 0.8020 - val_loss: 0.5137 - val_acc: 0.7592
Epoch 27/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.4233 - acc: 0.8024Epoch 00027: val_acc did not improve
258745/258745 [==============================] - 293s 1ms/step - loss: 0.4233 - acc: 0.8023 - val_loss: 0.5271 - val_acc: 0.7554
Epoch 28/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.4201 - acc: 0.8044Epoch 00028: val_acc did not improve
258745/258745 [==============================] - 303s 1ms/step - loss: 0.4201 - acc: 0.8044 - val_loss: 0.5196 - val_acc: 0.7527
Epoch 29/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.4213 - acc: 0.8032Epoch 00029: val_acc did not improve
258745/258745 [==============================] - 308s 1ms/step - loss: 0.4213 - acc: 0.8032 - val_loss: 0.5323 - val_acc: 0.7525
Epoch 30/50
258688/258745 [============================>.] - ETA: 0s - loss: 0.4202 - acc: 0.8043Epoch 00030: val_acc did not improve
258745/258745 [==============================] - 310s 1ms/step - loss: 0.4202 - acc: 0.8043 - val_loss: 0.5235 - val_acc: 0.7540

Metrics on test dataset
precision: [ 0.79246108  0.71280197]
recall: [ 0.85344117  0.61940099]
fscore: [ 0.82182148  0.6628273 ]
support: [50942 29916]
[[43476  7466]
 [11386 18530]]
Accuracy: 62006.0/(43476.0+7466.0+11386.0+18530.0) = 0.7668505280862747